{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Reference : https://www.tensorflow.org/tutorials/text/transformer?hl=zh-cn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from pprint import pprint\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"E:\\\\Coding\\\\Projects\\\\transformer\\\\Data file\"\n",
    "en_vocab_file = os.path.join(output_dir, \"en_vocab\")\n",
    "zh_vocab_file = os.path.join(output_dir, \"zh_vocab\")\n",
    "checkpoint_path = os.path.join(output_dir, \"checkpoints\")\n",
    "log_dir = os.path.join(output_dir, 'logs')\n",
    "download_dir = \"tensorflow-datasets/downloads\"\n",
    "\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{NamedSplit('train'): ['newscommentary_v14',\n",
      "                       'wikititles_v1',\n",
      "                       'uncorpus_v1',\n",
      "                       'casia2015',\n",
      "                       'casict2011',\n",
      "                       'casict2015',\n",
      "                       'datum2015',\n",
      "                       'datum2017',\n",
      "                       'neu2017'],\n",
      " NamedSplit('validation'): ['newstest2018']}\n"
     ]
    }
   ],
   "source": [
    "## reference:https://www.tensorflow.org/datasets/catalog/wmt_t2t_translate\n",
    "translate_builder = tfds.builder(\"wmt19_translate/zh-en\")\n",
    "pprint(translate_builder.subsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Using custom data configuration zh-en\n"
     ]
    }
   ],
   "source": [
    "## I use sub-dataset:newscommentary\n",
    "## download the data\n",
    "## extract the data to csv. file\n",
    "## load every row in the file\n",
    "## shuffle data\n",
    "## change the data to TFR data, reference: https://www.tensorflow.org/guide/data#consuming_tfrecord_data\n",
    "\n",
    "config = tfds.translate.wmt.WmtConfig(version=tfds.core.Version('0.0.3', experiments={tfds.core.Experiment.S3: False}),\n",
    "                                      language_pair=(\"zh\", \"en\"),subsets={tfds.Split.TRAIN: [\"newscommentary_v14\"]})\n",
    "\n",
    "builder = tfds.builder(\"wmt_translate\", config=config)\n",
    "builder.download_and_prepare(download_dir=output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(NamedSplit('train')(tfds.percent[0:30]),\n",
       " NamedSplit('train')(tfds.percent[30:31]),\n",
       " NamedSplit('train')(tfds.percent[31:100]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## use 30% of original dataset as train data and 1% as val data because original dataset is too huge\n",
    "\n",
    "train_part = 30\n",
    "val_part = 1\n",
    "drop_part = 100 - train_part - val_part\n",
    "\n",
    "split = tfds.Split.TRAIN.subsplit([train_part, val_part, drop_part])\n",
    "split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_OptionsDataset shapes: ((), ()), types: (tf.string, tf.string)>\n",
      "<_OptionsDataset shapes: ((), ()), types: (tf.string, tf.string)>\n"
     ]
    }
   ],
   "source": [
    "## as_supervised: bool, if True, the returned tf.data.Dataset will have a 2-tuple structure (input, label). \n",
    "## If False, the default, the returned tf.data.Dataset will have a dictionary with all the features.\n",
    "\n",
    "examples = builder.as_dataset(split=split, as_supervised=True)\n",
    "train_examples, val_examples, _ = examples\n",
    "\n",
    "print(train_examples)\n",
    "print(val_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(b'Making Do With More', shape=(), dtype=string)\n",
      "tf.Tensor(b'\\xe5\\xa4\\x9a\\xe5\\x8a\\xb3\\xe5\\xba\\x94\\xe5\\xa4\\x9a\\xe5\\xbe\\x97', shape=(), dtype=string)\n",
      "----------\n",
      "tf.Tensor(b'If the Putins, Erdo\\xc4\\x9fans, and Orb\\xc3\\xa1ns of the world want to continue to benefit economically from the open international system, they cannot simply make up their own rules.', shape=(), dtype=string)\n",
      "tf.Tensor(b'\\xe5\\xa6\\x82\\xe6\\x9e\\x9c\\xe6\\x99\\xae\\xe4\\xba\\xac\\xe3\\x80\\x81\\xe5\\x9f\\x83\\xe5\\xb0\\x94\\xe5\\xa4\\x9a\\xe5\\xae\\x89\\xe5\\x92\\x8c\\xe6\\xac\\xa7\\xe5\\xb0\\x94\\xe7\\x8f\\xad\\xe5\\xb8\\x8c\\xe6\\x9c\\x9b\\xe7\\xbb\\xa7\\xe7\\xbb\\xad\\xe4\\xba\\xab\\xe6\\x9c\\x89\\xe5\\xbc\\x80\\xe6\\x94\\xbe\\xe5\\x9b\\xbd\\xe9\\x99\\x85\\xe4\\xbd\\x93\\xe7\\xb3\\xbb\\xe6\\x8f\\x90\\xe4\\xbe\\x9b\\xe7\\x9a\\x84\\xe7\\xbb\\x8f\\xe6\\xb5\\x8e\\xe5\\x88\\xa9\\xe7\\x9b\\x8a\\xef\\xbc\\x8c\\xe5\\xb0\\xb1\\xe4\\xb8\\x8d\\xe8\\x83\\xbd\\xe7\\xae\\x80\\xe5\\x8d\\x95\\xe5\\x9c\\xb0\\xe5\\x88\\xb6\\xe5\\xae\\x9a\\xe8\\x87\\xaa\\xe5\\xb7\\xb1\\xe7\\x9a\\x84\\xe8\\xa7\\x84\\xe5\\x88\\x99\\xe3\\x80\\x82', shape=(), dtype=string)\n",
      "----------\n",
      "tf.Tensor(b'This ceiling can be raised only in a deep depression or other exceptional circumstances, allowing for counter-cyclical policy so long as it is agreed that the additional deficit is cyclical, rather than structural.', shape=(), dtype=string)\n",
      "tf.Tensor(b'\\xe5\\x8f\\xaa\\xe6\\x9c\\x89\\xe5\\x9c\\xa8\\xe5\\x8f\\x91\\xe7\\x94\\x9f\\xe6\\xb7\\xb1\\xe5\\xba\\xa6\\xe8\\x90\\xa7\\xe6\\x9d\\xa1\\xe6\\x88\\x96\\xe5\\x85\\xb6\\xe4\\xbb\\x96\\xe5\\x8f\\x8d\\xe5\\xb8\\xb8\\xe4\\xba\\x8b\\xe4\\xbb\\xb6\\xe6\\x97\\xb6\\xef\\xbc\\x8c\\xe8\\xbf\\x99\\xe4\\xb8\\x80\\xe4\\xb8\\x8a\\xe9\\x99\\x90\\xe6\\x89\\x8d\\xe8\\x83\\xbd\\xe5\\x81\\x9a\\xe5\\x87\\xba\\xe8\\xb0\\x83\\xe6\\x95\\xb4\\xef\\xbc\\x8c\\xe4\\xbb\\xa5\\xe4\\xbe\\xbf\\xe8\\xae\\xa9\\xe5\\x8f\\x8d\\xe5\\x91\\xa8\\xe6\\x9c\\x9f\\xe6\\x94\\xbf\\xe7\\xad\\x96\\xe5\\xae\\x9e\\xe6\\x96\\xbd\\xe8\\xb6\\xb3\\xe5\\xa4\\x9f\\xe7\\x9a\\x84\\xe9\\x95\\xbf\\xe5\\xba\\xa6\\xef\\xbc\\x8c\\xe4\\xbd\\xbf\\xe4\\xba\\xba\\xe4\\xbb\\xac\\xe4\\xb8\\x80\\xe8\\x87\\xb4\\xe8\\xae\\xa4\\xe4\\xb8\\xba\\xe5\\xa2\\x9e\\xe5\\x8a\\xa0\\xe7\\x9a\\x84\\xe8\\xb5\\xa4\\xe5\\xad\\x97\\xe6\\x98\\xaf\\xe5\\x91\\xa8\\xe6\\x9c\\x9f\\xe6\\x80\\xa7\\xe7\\x9a\\x84\\xef\\xbc\\x8c\\xe8\\x80\\x8c\\xe4\\xb8\\x8d\\xe6\\x98\\xaf\\xe7\\xbb\\x93\\xe6\\x9e\\x84\\xe6\\x80\\xa7\\xe7\\x9a\\x84\\xe3\\x80\\x82', shape=(), dtype=string)\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "## sentence in the train data are presented by unicode in two languages as tf.tensor type\n",
    "\n",
    "for en, zh in train_examples.take(3):\n",
    "    print(en)\n",
    "    print(zh)\n",
    "    print('-' * 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "Making Do With More\n",
      "多劳应多得\n",
      "----------------------------------------------------------------------------------------------------\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "If the Putins, Erdoğans, and Orbáns of the world want to continue to benefit economically from the open international system, they cannot simply make up their own rules.\n",
      "如果普京、埃尔多安和欧尔班希望继续享有开放国际体系提供的经济利益，就不能简单地制定自己的规则。\n",
      "----------------------------------------------------------------------------------------------------\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "This ceiling can be raised only in a deep depression or other exceptional circumstances, allowing for counter-cyclical policy so long as it is agreed that the additional deficit is cyclical, rather than structural.\n",
      "只有在发生深度萧条或其他反常事件时，这一上限才能做出调整，以便让反周期政策实施足够的长度，使人们一致认为增加的赤字是周期性的，而不是结构性的。\n",
      "----------------------------------------------------------------------------------------------------\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "Fascist and communist regimes of the past, which followed a similar instrumentalist approach to democracy, come to mind here.\n",
      "在此我们想起了过去的法西斯主义和共产主义。 它们都相似地将民主作为实现其目的的工具。\n",
      "----------------------------------------------------------------------------------------------------\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "For nearly 70 years since then, the peninsula has been divided, and now it may be the world’s most dangerous flashpoint.\n",
      "此后近70年来，朝鲜半岛一直处于分裂状态，如今它可能是全世界最危险的爆点。\n",
      "----------------------------------------------------------------------------------------------------\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "The eurozone’s collapse (and, for all practical purposes, that of the EU itself) forces a major realignment of European politics.\n",
      "欧元区的瓦解强迫欧洲政治进行一次重大改组。\n",
      "----------------------------------------------------------------------------------------------------\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "With energy and enthusiasm, Burden turned that operation into a thriving health (not health-care) agency that covers three cities and about 300,000 people on the western edge of Los Angeles.\n",
      "在能量与激情的推动下，波顿将BCHD打造成了欣欣向荣的健康（而非医疗）机构，其服务范围覆盖了洛杉矶西侧三座城市的30万人。\n",
      "----------------------------------------------------------------------------------------------------\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "The result could be a world of fragmented blocs – an outcome that would undermine not only global prosperity, but also cooperation on shared challenges.\n",
      "其结果可能是一个四分五裂的世界 — — 这一结果不但会破坏全球繁荣，也会破坏面对共同挑战的合作。\n",
      "----------------------------------------------------------------------------------------------------\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "Among the questions being asked by NGOs, the UN, and national donors is how to prevent the recurrence of past mistakes.\n",
      "现在NGO们、联合国和捐助国们问得最多的一个问题就是如何避免再犯过去的错误。\n",
      "----------------------------------------------------------------------------------------------------\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "Managing the rise of NCDs will require long-term thinking, and government leaders will have to make investments that might pay off only after they are no longer in office.\n",
      "管理NCD的增加需要长期思维，政府领导人必须进行要在他们离任多年后才能收回成本的投资。\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "## decode\n",
    "\n",
    "sample_examples = []\n",
    "num_samples = 10\n",
    "\n",
    "for en_t, zh_t in train_examples.take(num_samples):\n",
    "    en = en_t.numpy().decode(\"utf-8\")\n",
    "    zh = zh_t.numpy().decode(\"utf-8\")\n",
    "    \n",
    "    print(type(en_t))\n",
    "    print(en)\n",
    "    print(zh)\n",
    "    print('-' * 100)\n",
    "  \n",
    "   \n",
    "    sample_examples.append((en, zh))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data from corpus： E:\\Coding\\Projects\\transformer\\Data file\\en_vocab\n",
      "corpus size：8135\n",
      "first ten subwords：[', ', 'the_', 'of_', 'to_', 'and_', 's_', 'in_', 'a_', 'that_', 'is_']\n"
     ]
    }
   ],
   "source": [
    "## build corpus\n",
    "\n",
    "try:\n",
    "    subword_encoder_en = tfds.features.text.SubwordTextEncoder.load_from_file(en_vocab_file)\n",
    "    print(f'loading data from corpus： {en_vocab_file}')\n",
    "except:\n",
    "    print('building corpus....')\n",
    "    subword_encoder_en = tfds.features.text.SubwordTextEncoder.build_from_corpus((en.numpy() for en, _ in train_examples), \n",
    "                         target_vocab_size=2**13) \n",
    "  \n",
    "    subword_encoder_en.save_to_file(en_vocab_file)\n",
    "  \n",
    "\n",
    "\n",
    "print(f'corpus size：{subword_encoder_en.vocab_size}')\n",
    "print(f'first ten subwords：{subword_encoder_en.subwords[:10]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2700, 7911, 10, 8, 1169, 42, 161, 5, 125, 2026, 7, 2, 7428, 7925]\n",
      "('Taiwan is a nice country and I study in the Netherlands.',\n",
      " 'Taiwan is a nice country and I study in the Netherlands.')\n"
     ]
    }
   ],
   "source": [
    "## demo\n",
    "\n",
    "sample_string = 'Taiwan is a nice country and I study in the Netherlands.'\n",
    "indices = subword_encoder_en.encode(sample_string)\n",
    "decoded_string = subword_encoder_en.decode(indices)\n",
    "\n",
    "print(indices)\n",
    "assert decoded_string == sample_string\n",
    "pprint((sample_string, decoded_string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index     Subword\n",
      "---------------\n",
      " 2700     Taiwan\n",
      " 7911      \n",
      "   10     is \n",
      "    8     a \n",
      " 1169     nic\n",
      "   42     e \n",
      "  161     country \n",
      "    5     and \n",
      "  125     I \n",
      " 2026     study \n",
      "    7     in \n",
      "    2     the \n",
      " 7428     Netherlands\n",
      " 7925     .\n"
     ]
    }
   ],
   "source": [
    "print(\"{0:10}{1:6}\".format(\"Index\", \"Subword\"))\n",
    "print(\"-\" * 15)\n",
    "for idx in indices:\n",
    "    subword = subword_encoder_en.decode([idx])\n",
    "    print('{0:5}{1:6}'.format(idx, ' ' * 5 + subword))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data from corpus： E:\\Coding\\Projects\\transformer\\Data file\\zh_vocab\n",
      "corpus size：4201\n",
      "first ten subwords：['的', '，', '。', '国', '在', '是', '一', '和', '不', '这']\n"
     ]
    }
   ],
   "source": [
    "## max_subword_length=1:every Chinese character can be seen as a subword in corpus.\n",
    "\n",
    "try:\n",
    "    subword_encoder_zh = tfds.features.text.SubwordTextEncoder.load_from_file(zh_vocab_file)\n",
    "    print(f'loading data from corpus： {zh_vocab_file}')\n",
    "except:\n",
    "    print('building corpus....')\n",
    "    subword_encoder_zh = tfds.features.text.SubwordTextEncoder.build_from_corpus((zh.numpy() for _, zh in train_examples), \n",
    "                         target_vocab_size=2**13, max_subword_length=1) # a Chinese character is a subword in corpus\n",
    "    \n",
    "    subword_encoder_zh.save_to_file(zh_vocab_file)\n",
    "\n",
    "    \n",
    "print(f'corpus size：{subword_encoder_zh.vocab_size}')\n",
    "print(f'first ten subwords：{subword_encoder_zh.subwords[:10]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "多劳应多得\n",
      "[48, 557, 116, 48, 81]\n"
     ]
    }
   ],
   "source": [
    "## demo \n",
    "\n",
    "sample_string = sample_examples[0][1]\n",
    "indices = subword_encoder_zh.encode(sample_string)\n",
    "print(sample_string)\n",
    "print(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## add BOS and EOS to the sequence, use subword_encoder_en.vocab_size/+1 as index of BOS/EOS\n",
    "\n",
    "def encode(en_t, zh_t):\n",
    "   \n",
    "    en_indices = [subword_encoder_en.vocab_size] + subword_encoder_en.encode(en_t.numpy())\\\n",
    "               + [subword_encoder_en.vocab_size + 1]\n",
    "    \n",
    "    zh_indices = [subword_encoder_zh.vocab_size] + subword_encoder_zh.encode(zh_t.numpy())\\\n",
    "               + [subword_encoder_zh.vocab_size + 1]\n",
    "  \n",
    "    return en_indices, zh_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## tensor doesn't have the numpy attribute, can't directly use dataset.map(en_t,zh_t)\n",
    "## tf.py_function allows expressing computations in a TensorFlow graph as Python functions.\n",
    "\n",
    "def tf_encode(en_t, zh_t):\n",
    " \n",
    "    return tf.py_function(encode, [en_t, zh_t], [tf.int64, tf.int64])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## build tf.filter\n",
    "\n",
    "max_len = 40\n",
    "\n",
    "def filter_max_length(en, zh, max_length=max_len):\n",
    "    \n",
    "  # tf.logical_and == (True,True), only return when en and zh are both True\n",
    "\n",
    "    return tf.logical_and(tf.size(en) <= max_length,tf.size(zh) <= max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "buffer_size = 15000\n",
    "\n",
    "train_encode = train_examples.map(tf_encode)  # output:(en_seq, zh_seq)\n",
    "train_filt = train_encode.filter(filter_max_length).cache()  # output：(en_index, zh_index)\n",
    "train_shuffle = train_filt.shuffle(buffer_size)  # 將例子洗牌確保隨機性\n",
    "train_dataset = train_shuffle.padded_batch(batch_size, padded_shapes=([-1], [-1])).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "val_encode = train_examples.map(tf_encode)\n",
    "val_filt = train_encode.filter(filter_max_length).cache() \n",
    "val_shuffle = train_filt.shuffle(buffer_size) \n",
    "val_dataset = train_shuffle.padded_batch(batch_size, padded_shapes=([-1], [-1])).prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('You know nothing.', '你什么也不知道。'), ('Long may sunshine!', '愿阳光明媚！')]\n"
     ]
    }
   ],
   "source": [
    "## make demo examples\n",
    "\n",
    "demo_examples = [\n",
    "    (\"You know nothing.\", \"你什么也不知道。\"),\n",
    "    (\"Long may sunshine!\", \"愿阳光明媚！\"),\n",
    "]\n",
    "pprint(demo_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inp: tf.Tensor(\n",
      "[[8135 2634 7911  562  581 2150 7925 8136    0]\n",
      " [8135 1210   64   98 5105 1405  687 7912 8136]], shape=(2, 9), dtype=int64)\n",
      "\n",
      "tar: tf.Tensor(\n",
      "[[4201  621  338  231   43    9  418  273    3 4202]\n",
      " [4201  524 1211  830  189 3276 1629 4202    0    0]], shape=(2, 10), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "batch_size_demo = 2\n",
    "demo_examples = tf.data.Dataset.from_tensor_slices((\n",
    "    [en for en, _ in demo_examples], [zh for _, zh in demo_examples]\n",
    "))\n",
    "\n",
    "\n",
    "# add padding token\n",
    "\n",
    "demo_dataset = demo_examples.map(tf_encode)\\\n",
    "  .padded_batch(batch_size_demo, padded_shapes=([-1], [-1]))\n",
    "\n",
    "# show\n",
    "\n",
    "inp, tar = next(iter(demo_dataset))\n",
    "print('inp:', inp)\n",
    "print('' * 10)\n",
    "print('tar:', tar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "## position encoding\n",
    "\n",
    "# PE(pos, 2i) = sin(pos / 10000^(2i/d_model))\n",
    "# PE(pos, 2i+1) = cos(pos / 10000^(2i/d_model))\n",
    "# pos.shape == (sentence_len,1)\n",
    "# d_model.shape == (1,d_model)\n",
    "# d_model == word embedding units\n",
    "# get_angles.shape:(sentence_len, d_model)\n",
    "\n",
    "def get_angles(pos, i, d_model):\n",
    "    \n",
    "    angle_rates = 1 / np.power(10000, (2 * (i//2)) / np.float32(d_model)) \n",
    "    \n",
    "    return pos * angle_rates\n",
    "\n",
    "def positional_encoding(position, d_model):\n",
    "    \n",
    "    # position  == max_seq_len\n",
    "    \n",
    "    angle_rads = get_angles(np.arange(position)[:, np.newaxis], \n",
    "                          np.arange(d_model)[np.newaxis, :],\n",
    "                          d_model)\n",
    "    \n",
    "    # sin.shape == (sentence_len,d_model/2)\n",
    "    # cos.shape == (sentence_len,d_model/2)\n",
    "    \n",
    "    sin = np.sin(angle_rads[:,0::2]) \n",
    "    cos = np.cos(angle_rads[:, 1::2]) \n",
    "    \n",
    "    # pos_embedding.shape ==(sentence_len,d_model)\n",
    "    \n",
    "    pos_encoding = tf.concat([sin,cos],axis=-1)\n",
    "    \n",
    "    # pos_embedding.shape ==(1, sentence_len, d_model)\n",
    "    \n",
    "    pos_encoding = pos_encoding[np.newaxis, ...]\n",
    "    \n",
    "    return tf.cast(pos_encoding, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(2, 9, 4), dtype=float32, numpy=\n",
       " array([[[ 0.01505223, -0.01816765,  0.04863017,  0.03451839],\n",
       "         [-0.00471901, -0.03347461,  0.00661217,  0.04263944],\n",
       "         [-0.03741904,  0.0162987 , -0.02005308, -0.04318934],\n",
       "         [-0.02287551,  0.0213968 ,  0.02386638,  0.01451081],\n",
       "         [ 0.04134926,  0.04590184, -0.04658299,  0.02239406],\n",
       "         [ 0.04545938,  0.04026873,  0.01543689,  0.03578669],\n",
       "         [ 0.00587896,  0.04076074, -0.03942049, -0.01949289],\n",
       "         [-0.03144058, -0.01643362,  0.00941877, -0.02804999],\n",
       "         [ 0.03923755,  0.00184336,  0.03753285, -0.00180028]],\n",
       " \n",
       "        [[ 0.01505223, -0.01816765,  0.04863017,  0.03451839],\n",
       "         [-0.0191102 , -0.01843125,  0.04677094, -0.01295252],\n",
       "         [-0.03195452, -0.00884617,  0.04023999,  0.01639371],\n",
       "         [ 0.04439774,  0.03465059, -0.01233953,  0.03018674],\n",
       "         [-0.03772911,  0.04060903, -0.00965424,  0.02662456],\n",
       "         [-0.04792821,  0.04831452,  0.02385906,  0.02973593],\n",
       "         [-0.02577896, -0.02118267,  0.04181449,  0.03406204],\n",
       "         [ 0.00742896,  0.02065426,  0.02974881,  0.00734647],\n",
       "         [-0.03144058, -0.01643362,  0.00941877, -0.02804999]]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(2, 10, 4), dtype=float32, numpy=\n",
       " array([[[ 0.0336815 ,  0.04831519, -0.00292831,  0.04247849],\n",
       "         [-0.02072674,  0.01831568, -0.00173951, -0.02158908],\n",
       "         [ 0.00731621,  0.04615181,  0.01750444, -0.02598125],\n",
       "         [-0.0160775 , -0.04454218, -0.01585361, -0.03658035],\n",
       "         [ 0.02725017, -0.00504459,  0.04141184, -0.01012856],\n",
       "         [ 0.0230474 ,  0.00540747,  0.03790546, -0.04082   ],\n",
       "         [ 0.0016703 , -0.02600184,  0.01323172, -0.03388675],\n",
       "         [ 0.01764438,  0.0332181 , -0.02330616, -0.02791836],\n",
       "         [ 0.00724801, -0.04026889, -0.03373075, -0.01725874],\n",
       "         [-0.00252495, -0.00352658,  0.01846405, -0.03989297]],\n",
       " \n",
       "        [[ 0.0336815 ,  0.04831519, -0.00292831,  0.04247849],\n",
       "         [-0.03660611, -0.04944899, -0.04753276,  0.04761963],\n",
       "         [-0.04961077, -0.01513363, -0.02726718, -0.03511251],\n",
       "         [-0.0022372 , -0.00852648, -0.02401493,  0.0279646 ],\n",
       "         [ 0.01352093, -0.01880418,  0.04885269,  0.04071944],\n",
       "         [-0.01217799, -0.03226995,  0.01633083,  0.03305167],\n",
       "         [-0.01128221,  0.01609263, -0.03672148,  0.00667126],\n",
       "         [-0.00252495, -0.00352658,  0.01846405, -0.03989297],\n",
       "         [-0.04315757,  0.03780004,  0.00626341, -0.04123787],\n",
       "         [-0.04315757,  0.03780004,  0.00626341, -0.04123787]]],\n",
       "       dtype=float32)>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## embedding layer demo\n",
    "\n",
    "vocab_size_en_demo = subword_encoder_en.vocab_size + 2\n",
    "vocab_size_zh_demo = subword_encoder_zh.vocab_size + 2\n",
    "\n",
    "d_model_demo = 4\n",
    "embedding_layer_en = tf.keras.layers.Embedding(vocab_size_en_demo, d_model_demo)\n",
    "embedding_layer_zh = tf.keras.layers.Embedding(vocab_size_zh_demo, d_model_demo)\n",
    "\n",
    "emb_inp = embedding_layer_en(inp)\n",
    "emb_tar = embedding_layer_zh(tar)\n",
    "emb_inp, emb_tar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "## build padding mask\n",
    "\n",
    "def create_padding_mask(seq):\n",
    "\n",
    "    mask = tf.cast(tf.equal(seq, 0), tf.float32)\n",
    "    return mask[:, tf.newaxis, tf.newaxis, :] #　broadcasting to fit the attention layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "## scaled_dot_product_attention\n",
    "\n",
    "def scaled_dot_product_attention(q, k, v, mask):\n",
    "   \n",
    "    # dot product q and k \n",
    "    matmul_qk = tf.matmul(q, k, transpose_b=True)  # (..., seq_len_q, seq_len_k)\n",
    "  \n",
    "    dk = tf.cast(tf.shape(k)[-1], tf.float32)  \n",
    "    scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)  # scale by sqrt(dk)\n",
    "\n",
    "    # add mask\n",
    "    if mask is not None:\n",
    "        scaled_attention_logits += (mask * -1e9) # * -1e9 make the value after doing softmax round to 0\n",
    "\n",
    "    # do the softmax and sum up the v vector to 1\n",
    "    attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)  # (..., seq_len_q, seq_len_k)\n",
    "  \n",
    "    # do the weighted average of v with attention_weights\n",
    "    output = tf.matmul(attention_weights, v)  # (..., seq_len_q, depth_v)\n",
    "\n",
    "    return output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "if attention weights ==(3,3) \n",
    "eg: [[1,2,3]\n",
    "     [2,3,4]\n",
    "     [3,4,6]]\n",
    "     \n",
    "--------------->\n",
    "\n",
    "   [[1,0,0]\n",
    "    [2,3,0]\n",
    "    [3,4,6]]\n",
    "    \n",
    "former words would not see latter words\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def create_look_ahead_mask(size):\n",
    "    mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
    "    return mask  # (seq_len, seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0. 1. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 0.]], shape=(3, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "## matrix demo\n",
    "\n",
    "print(1-tf.linalg.band_part(tf.ones((3, 3)), -1, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "## build multiheadAttention\n",
    "\n",
    "# 在初始的時候指定輸出維度 `d_model` & `num_heads，\n",
    "# 在呼叫的時候輸入 `v`, `k`, `q` 以及 `mask`\n",
    "# 輸出跟 scaled_dot_product_attention 函式一樣有兩個：\n",
    "# output.shape            == (batch_size, seq_len_q, d_model)\n",
    "# attention_weights.shape == (batch_size, num_heads, seq_len_q, seq_len_k)\n",
    "\n",
    "\"\"\"\n",
    "convert Q, K and V to (....., d_model) shape ，\n",
    "seperate each of them to N (....,depth) tensors and put them in scale dot product layer to get N results,\n",
    "and concat them.\n",
    "\n",
    "q->Wq->Q->split->q0,q1,q2\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.num_heads = num_heads # seperate 'd_model' to N heads\n",
    "        self.d_model = d_model \n",
    "        \n",
    "        assert d_model % self.num_heads == 0\n",
    "        \n",
    "        self.depth = d_model // self.num_heads # -1 dim of every tensor\n",
    "        \n",
    "        # linear transformation \n",
    "        \n",
    "        self.Wq = tf.keras.layers.Dense(d_model)\n",
    "        self.Wk = tf.keras.layers.Dense(d_model)\n",
    "        self.Wv = tf.keras.layers.Dense(d_model)\n",
    "        \n",
    "        # linear transformation after concatenate\n",
    "            \n",
    "        self.dense = tf.keras.layers.Dense(d_model) \n",
    "        \n",
    "        \n",
    "    def split_heads(self, x, batch_size):\n",
    "    \n",
    "        # original x.shape == (batch_size, senquence_len, d_model)\n",
    "        # d_model = num_heads * depth\n",
    "        # we need x ->(batch_size, num_heads, seq_len, depth)\n",
    "\n",
    "        \n",
    "        # (batch_size, seq_len, num_heads, depth)\n",
    "        reshaped_x = tf.reshape(x, shape=(batch_size, -1, self.num_heads, self.depth))\n",
    "        \n",
    "        # transpose the shape to (batch_size, num_heads, seq_len, depth), we need this shape for calculation of scale dot product\n",
    "        \n",
    "        split_output = tf.transpose(reshaped_x, perm=[0, 2, 1, 3]) \n",
    "        \n",
    "        return split_output\n",
    "    \n",
    "    def call(self, v, k, q, mask):\n",
    "        \n",
    "        batch_size = tf.shape(q)[0]\n",
    "        \n",
    "\n",
    "        \n",
    "        q = self.Wq(q)  # (batch_size, seq_len, d_model) \n",
    "        k = self.Wk(k)  # (batch_size, seq_len, d_model)\n",
    "        v = self.Wv(v)  # (batch_size, seq_len, d_model)\n",
    "        \n",
    "\n",
    "        \n",
    "        q = self.split_heads(q, batch_size)  # (batch_size, num_heads, seq_len_q, depth)\n",
    "        k = self.split_heads(k, batch_size)  # (batch_size, num_heads, seq_len_k, depth)\n",
    "        v = self.split_heads(v, batch_size)  # (batch_size, num_heads, seq_len_v, depth)\n",
    "    \n",
    "        # scaled_attention_output.shape == (batch_size, num_heads, seq_len_q, depth)\n",
    "        # attention_weights.shape == (batch_size, num_heads, seq_len_q, seq_len_k)\n",
    "        \n",
    "\n",
    "        # seq_len_q  == seq_len_v\n",
    "        \n",
    "        scaled_attention_output, attention_weights = scaled_dot_product_attention(q, k, v, mask)\n",
    "        \n",
    "        scaled_attention = tf.transpose(scaled_attention_output, perm=[0, 2, 1, 3])  # (batch_size, seq_len_q, num_heads, depth)\n",
    "        \n",
    "        # reshape\n",
    "        \n",
    "        concat_attention = tf.reshape(scaled_attention, \n",
    "                                  (batch_size, -1, self.d_model))  # (batch_size, seq_len_q, d_model)\n",
    "        \n",
    "        # now the shape is (batch_size, seq_len_q, d_model)\n",
    "\n",
    "        \n",
    "        output = self.dense(concat_attention)  # (batch_size, seq_len_q, d_model)\n",
    "        \n",
    "        return output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Build Feed Forward \n",
    "\n",
    "def point_wise_feed_forward_network(d_model, dff):\n",
    "  \n",
    "    return tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(dff, activation='relu'),  # (batch_size, seq_len, dff)\n",
    "        tf.keras.layers.Dense(d_model)  # (batch_size, seq_len, d_model)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "## build encoder layer\n",
    "\n",
    "# there are N EncoderLayers in Encoder，there are two sub-layers: MHA & FFN in Encoder layer.\n",
    "\n",
    "\"\"\"\n",
    "x->self attention->add & normalize  & dropout\n",
    " ->feed forward->add & normalize & dropout\n",
    "\"\"\"\n",
    "\n",
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "    \n",
    "    # set dropout rate to 0.1\n",
    "    \n",
    "    def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "\n",
    "        self.mha = MultiHeadAttention(d_model, num_heads)\n",
    "        self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
    "\n",
    "        # layer norm\n",
    "        \n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "    \n",
    "        # dropout layer\n",
    "        \n",
    "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "    \n",
    "    def call(self, x, training, mask):\n",
    "        \n",
    "        # x.shape == (batch_Size,seq_len, embedding_units)\n",
    "        # attn.shape == (batch_size, seq_len,d_model)\n",
    "        # output1.shape == (batch_size, seq_len,d_model)\n",
    "        \n",
    "        # sub-layer 1: MHA\n",
    "\n",
    "        \n",
    "        attn_output, attn = self.mha(x, x, x, mask)  #self_attention\n",
    "        attn_output = self.dropout1(attn_output, training=training) # dropout \n",
    "        out1 = self.layernorm1(x + attn_output)  # add & norm, 且embedding_units == d_model\n",
    "    \n",
    "        # sub-layer 2: FFN\n",
    "        # ffm_output.shape == (batch_size, seq_len,d_model)\n",
    "        # output2.shape == (batch_size, seq_len,d_model)\n",
    "        \n",
    "        ffn_output = self.ffn(out1) \n",
    "        ffn_output = self.dropout2(ffn_output, training=training)  # training\n",
    "        out2 = self.layernorm2(out1 + ffn_output)\n",
    "    \n",
    "        return out2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "## build decoder layer\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "x->self attention->add & nomalize & dropout ->out1\n",
    " out1, encoding_output-> attention -> add & nomalize & dropout ->out2\n",
    " out2 ->ffn ->add & nomalize & dropout->out3\n",
    " \n",
    "\"\"\"\n",
    "\n",
    "# Decoder:N DecoderLayers，\n",
    "# DecoderLayer: 3 sub-layers : MHA, MHA focusing on encoder , & FFN\n",
    "\n",
    "class DecoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        \n",
    "        self.mha1 = MultiHeadAttention(d_model, num_heads)\n",
    "        self.mha2 = MultiHeadAttention(d_model, num_heads) # attention of encoder & decoder\n",
    "        self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
    " \n",
    "        # LayerNorm\n",
    "    \n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "    \n",
    "        # Dropout\n",
    "        \n",
    "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout3 = tf.keras.layers.Dropout(rate)\n",
    "    \n",
    "    \n",
    "    def call(self, x, enc_output, training, \n",
    "           combined_mask, inp_padding_mask):\n",
    "        \n",
    "        # x.shape == (batch_size,seq_len, d_model)       \n",
    "        # attn_weights1 : (batch_size, num_heads, target_seq_len, target_seq_len)\n",
    "        # attn_weights2 : (batch_size, num_heads, target_seq_len, input_seq_len)\n",
    "        # we also need look ahead mask and padding mask \n",
    "        \n",
    "        attn1, attn_weights1 = self.mha1(x, x, x, combined_mask)\n",
    "        attn1 = self.dropout1(attn1, training=training)\n",
    "        out1 = self.layernorm1(attn1 + x)\n",
    "    \n",
    "        # sub-layer 2: Decoder layer attention for Encoder output\n",
    "        \n",
    "        attn2, attn_weights2 = self.mha2(\n",
    "                                enc_output, enc_output, out1, inp_padding_mask)  # (batch_size, target_seq_len, d_model)\n",
    "        \n",
    "        attn2 = self.dropout2(attn2, training=training)\n",
    "        out2 = self.layernorm2(attn2 + out1)  # (batch_size, target_seq_len, d_model)\n",
    "        \n",
    "        ffn_output = self.ffn(out2)  # (batch_size, target_seq_len, d_model)\n",
    "\n",
    "        ffn_output = self.dropout3(ffn_output, training=training)\n",
    "        out3 = self.layernorm3(ffn_output + out2)  # (batch_size, target_seq_len, d_model)\n",
    "        \n",
    "        return out3, attn_weights1, attn_weights2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "## build encoder\n",
    "\n",
    "# - num_layers: N\n",
    "\n",
    "class Encoder(tf.keras.layers.Layer):\n",
    "    \n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size,\n",
    "               rate=0.1):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "    \n",
    "        self.embedding = tf.keras.layers.Embedding(input_vocab_size, d_model)\n",
    "        \n",
    "        # pos_encoding.shape == (1,input_vocab_size, d_model)\n",
    "        \n",
    "        self.pos_encoding = positional_encoding(input_vocab_size, self.d_model)\n",
    "    \n",
    "        self.enc_layers = [EncoderLayer(d_model, num_heads, dff, rate) \n",
    "                           for _ in range(num_layers)]\n",
    "\n",
    "        self.dropout = tf.keras.layers.Dropout(rate)\n",
    "        \n",
    "    def call(self, x, training, mask):\n",
    "        \n",
    "        # input x.shape == (batch_size, input_seq_len)\n",
    "        # output.shape of every layer:(batch_size, input_seq_len, d_model)\n",
    "        \n",
    "        input_seq_len = tf.shape(x)[1]\n",
    "    \n",
    "        # after embedding:x.shape == (batch_size, input_seq_len, d_model)\n",
    "        \n",
    "        x = self.embedding(x)\n",
    "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "        x += self.pos_encoding[:, :input_seq_len, :]\n",
    "        \n",
    "        x = self.dropout(x, training=training)\n",
    "        \n",
    "        for i, enc_layer in enumerate(self.enc_layers):\n",
    "            x = enc_layer(x, training, mask)\n",
    "        \n",
    "        # x.shape == (batch_size, input_seq_len, d_model)\n",
    "          \n",
    "        return x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "## build decoder\n",
    "\n",
    "class Decoder(tf.keras.layers.Layer):\n",
    "    \n",
    "\n",
    "    \n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, target_vocab_size, \n",
    "               rate=0.1):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        \n",
    "        self.embedding = tf.keras.layers.Embedding(target_vocab_size, self.d_model)\n",
    "        self.pos_encoding = positional_encoding(target_vocab_size, self.d_model)\n",
    "    \n",
    "        self.dec_layers = [DecoderLayer(d_model, num_heads, dff, rate) \n",
    "                       for _ in range(num_layers)]\n",
    "        self.dropout = tf.keras.layers.Dropout(rate)\n",
    "    \n",
    "    def call(self, x, enc_output, training, \n",
    "               combined_mask, inp_padding_mask):\n",
    "    \n",
    "        tar_seq_len = tf.shape(x)[1]\n",
    "        attention_weights = {}  # to store attention weights\n",
    "        \n",
    "        x = self.embedding(x)  # (batch_size, tar_seq_len, d_model)\n",
    "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "        x += self.pos_encoding[:, :tar_seq_len, :]\n",
    "        x = self.dropout(x, training=training)\n",
    "    \n",
    "        for i, dec_layer in enumerate(self.dec_layers):\n",
    "            x, block1, block2 = dec_layer(x, enc_output, training,\n",
    "                                    combined_mask, inp_padding_mask)\n",
    "        \n",
    "            attention_weights['decoder_layer{}_block1'.format(i + 1)] = block1\n",
    "            attention_weights['decoder_layer{}_block2'.format(i + 1)] = block2\n",
    "    \n",
    "        # x.shape == (batch_size, tar_seq_len, d_model)\n",
    "        \n",
    "        return x, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "## process of training\n",
    "\n",
    "# 1.initialize model\n",
    "# 2.define loss optimizer, define learning rate schedule\n",
    "# 3.train step \n",
    "# 4.train process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning rate = (d_model ** -0.5) * min(step_num ** -0.5, step_num *warm_up ** -1.5)\n",
    "# learning rate 先增後減\n",
    "\n",
    "class learning_rate_schedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    \n",
    "    # warmup_steps == 4000 in thesis\n",
    "    def __init__(self, d_model, warmup_steps=4000):\n",
    "        super(learning_rate_schedule, self).__init__()\n",
    "    \n",
    "        self.d_model = d_model\n",
    "        self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "\n",
    "        self.warmup_steps = warmup_steps\n",
    "    \n",
    "    def __call__(self, step):\n",
    "        \n",
    "        arg1 = tf.math.rsqrt(step)\n",
    "        arg2 = step * (self.warmup_steps ** -1.5)\n",
    "    \n",
    "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "set reduction to none because we don't want loss_object sum up the error in every position。\n",
    "we don't want the loss of <pad> token.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    \n",
    "    # set 1 to the non-zero value in seq \n",
    "    loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "                                  from_logits=True, reduction='none')\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))    \n",
    "    loss_ = loss_object(real, pred)\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask  # just calculate the loss of non padding value\n",
    "    \n",
    "    return tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "## prepare all the masks for Transformer\n",
    "\n",
    "def create_masks(inp, tar):\n",
    "    \n",
    "    # padding mask for encoder\n",
    "    \n",
    "    enc_padding_mask = create_padding_mask(inp)\n",
    "  \n",
    "    # padding mask for Decoder layer\n",
    "    \n",
    "    dec_padding_mask = create_padding_mask(inp)\n",
    "  \n",
    "    # combined_mask: padding mask of zh_seq and look ahead mask \n",
    "    \n",
    "    look_ahead_mask = create_look_ahead_mask(tf.shape(tar)[1])\n",
    "    dec_target_padding_mask = create_padding_mask(tar)\n",
    "    combined_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\n",
    "  \n",
    "    return enc_padding_mask, combined_mask, dec_padding_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "## build checkpoint directory path\n",
    "\n",
    "run_id = 'WMT19en-zh'\n",
    "checkpoint_path = os.path.join(checkpoint_path, run_id)\n",
    "log_dir = os.path.join(log_dir, run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "## build transformer\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "input of Encoder: en_seq.shape == （batch_size, inp_seq_len）\n",
    "input of Decoder: zh_seq.shape == （batch_size, inp_seq_len）\n",
    "\n",
    "output of Decoder:（batch_size, tar_seq_len, target_vocab_size）\n",
    "target_vocab_size represents the probability distribution of Chinese characters\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "class Transformer(tf.keras.Model):\n",
    "\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, \n",
    "               target_vocab_size, rate=0.1):\n",
    "        super(Transformer, self).__init__()\n",
    "\n",
    "        self.encoder = Encoder(num_layers, d_model, num_heads, dff, \n",
    "                           input_vocab_size, rate)\n",
    "\n",
    "        self.decoder = Decoder(num_layers, d_model, num_heads, dff, \n",
    "                           target_vocab_size, rate)\n",
    "    \n",
    "        self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n",
    "        \n",
    "        # set lr rate\n",
    "        self.learning_rate = learning_rate_schedule(d_model)\n",
    "        \n",
    "        self.train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "        self.train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
    "        \n",
    "        self.val_loss = tf.keras.metrics.Mean(name='val_loss')\n",
    "        self.val_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='val_accuracy')\n",
    "        \n",
    "        # optimizer\n",
    "        self.optimizer = tf.keras.optimizers.Adam(self.learning_rate, beta_1=0.9, beta_2=0.98, \n",
    "                                                  epsilon=1e-9)\n",
    "        \n",
    "        \n",
    "    def call(self, inp, tar, training, enc_padding_mask, \n",
    "           combined_mask, dec_padding_mask):\n",
    "\n",
    "        enc_output = self.encoder(inp, training, enc_padding_mask)  # (batch_size, inp_seq_len, d_model)\n",
    "    \n",
    "        # dec_output.shape == (batch_size, tar_seq_len, d_model)\n",
    "    \n",
    "        dec_output, attention_weights = self.decoder(\n",
    "                                        tar, enc_output, training, combined_mask, dec_padding_mask)\n",
    "    \n",
    "        final_output = self.final_layer(dec_output)  # (batch_size, tar_seq_len, target_vocab_size)\n",
    "    \n",
    "        return final_output, attention_weights\n",
    "    \n",
    "    #define train_step\n",
    "    \n",
    "    @tf.function\n",
    "    def train_step(self, inp, tar):\n",
    "        \n",
    "        # eg:use <start> to predict next word \n",
    "        tar_inp = tar[:, :-1]\n",
    "        tar_real = tar[:, 1:]\n",
    "        \n",
    "        # masks\n",
    "        enc_padding_mask, combined_mask, dec_padding_mask = create_masks(inp, tar_inp)\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            \n",
    "            predictions, _ = self.call(inp, tar_inp, True, \n",
    "                                        enc_padding_mask, \n",
    "                                        combined_mask, \n",
    "                                        dec_padding_mask)\n",
    "            \n",
    "            loss = loss_function(tar_real, predictions)\n",
    "        \n",
    "        gradients = tape.gradient(loss, self.trainable_variables)    \n",
    "        self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\n",
    "        \n",
    "\n",
    "        self.train_loss(loss) # store the loss\n",
    "        self.train_accuracy(tar_real, predictions) \n",
    "    \n",
    "    def val_step(self, inp, tar):\n",
    "        \n",
    "        tar_inp = tar[:, :-1]\n",
    "        tar_real = tar[:, 1:]\n",
    "        \n",
    "        enc_padding_mask, combined_mask, dec_padding_mask = create_masks(inp, tar_inp)\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            \n",
    "            predictions, _ = self.call(inp, tar_inp, False, \n",
    "                                        enc_padding_mask, \n",
    "                                        combined_mask, \n",
    "                                        dec_padding_mask)\n",
    "            \n",
    "            loss = loss_function(tar_real, predictions)\n",
    "        \n",
    "        gradients = tape.gradient(loss, self.trainable_variables)    \n",
    "        self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\n",
    "        \n",
    "\n",
    "        self.val_loss(loss) # store the loss\n",
    "        self.val_accuracy(tar_real, predictions) \n",
    "    \n",
    "\n",
    "    def train(self, num_epochs):\n",
    "        \n",
    "        ckpt = tf.train.Checkpoint(transformer=self,\n",
    "                           optimizer=self.optimizer)\n",
    "\n",
    "        ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n",
    "\n",
    "        if ckpt_manager.latest_checkpoint:\n",
    "            ckpt.restore(ckpt_manager.latest_checkpoint)\n",
    "  \n",
    "            last_epoch = int(ckpt_manager.latest_checkpoint.split(\"-\")[-1])\n",
    "            print(f'loading checkpoint..., model has trained {last_epoch} epochs。')\n",
    "        else:\n",
    "            last_epoch = 0\n",
    "            print(\"No checkpoint.\")\n",
    "        \n",
    "        summary_writer = tf.summary.create_file_writer(log_dir)\n",
    "        \n",
    "        print(f\"this Transformer has trained {last_epoch} epochs。\")\n",
    "        print(f\"the rest of epochs：{min(0, last_epoch - num_epochs)}\")\n",
    "        \n",
    "        for epoch in range(last_epoch, num_epochs):\n",
    "            \n",
    "            start_time = time.time()\n",
    "            \n",
    "            self.train_loss.reset_states()\n",
    "            self.train_accuracy.reset_states()\n",
    "            \n",
    "            self.val_loss.reset_states()\n",
    "            self.val_accuracy.reset_states()\n",
    "            \n",
    "            for (step_idx, (inp, tar)) in enumerate(train_dataset):\n",
    "                \n",
    "                self.train_step(inp, tar) \n",
    "            \n",
    "            for (step_idx, (inp, tar)) in enumerate(val_dataset):\n",
    "                \n",
    "                self.val_step(inp, tar) \n",
    "                \n",
    "             # save the model for every epoch \n",
    "            if (epoch + 1) % 1 == 0:\n",
    "                ckpt_save_path = ckpt_manager.save()\n",
    "                print ('Saving checkpoint for epoch {} at {}'.format(epoch+1,\n",
    "                                                                     ckpt_save_path))\n",
    "    \n",
    "             # write the loss and accuracy to TensorBoard \n",
    "    \n",
    "            with summary_writer.as_default():\n",
    "                tf.summary.scalar(\"train_loss\", self.train_loss.result(), step=epoch + 1)\n",
    "                tf.summary.scalar(\"train_acc\", self.train_accuracy.result(), step=epoch + 1)\n",
    "                tf.summary.scalar(\"val_loss\", self.val_loss.result(), step=epoch + 1)\n",
    "                tf.summary.scalar(\"val_acc\", self.val_accuracy.result(), step=epoch + 1)  \n",
    "           \n",
    "            print('Epoch {}, Running time: {:.2f}, Train Loss {:.4f},Train Accuracy {:.4f}'.format(epoch + 1, \n",
    "                                                                                time.time() - start_time, \n",
    "                                                                                self.train_loss.result(), \n",
    "                                                                                self.train_accuracy.result()))\n",
    "            \n",
    "            print('Epoch {}, Running time: {:.2f}, Val Loss {:.4f},Val Accuracy {:.4f}'.format(epoch + 1, \n",
    "                                                                                time.time() - start_time,\n",
    "                                                                                self.val_loss.result(),\n",
    "                                                                                self.val_accuracy.result()))\n",
    "            print('-'*100)\n",
    "            print('-'*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_vocab_size: 8137\n",
      "target_vocab_size: 4203\n"
     ]
    }
   ],
   "source": [
    "## create object of model\n",
    "\n",
    "d_model = 128\n",
    "num_layers = 4 \n",
    "dff = 512\n",
    "num_heads = 8\n",
    "\n",
    "input_vocab_size = subword_encoder_en.vocab_size + 2\n",
    "target_vocab_size = subword_encoder_zh.vocab_size + 2\n",
    "dropout_rate = 0.1  \n",
    "\n",
    "print(\"input_vocab_size:\", input_vocab_size)\n",
    "print(\"target_vocab_size:\", target_vocab_size)\n",
    "\n",
    "transformer = Transformer(num_layers, d_model, num_heads, dff,\n",
    "                          input_vocab_size, target_vocab_size, dropout_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No checkpoint.\n",
      "this Transformer has trained 0 epochs。\n",
      "the rest of epochs：-40\n",
      "WARNING:tensorflow:From C:\\Users\\Y.Liu\\Anaconda3\\envs\\DeepLearning\\lib\\site-packages\\tensorflow_core\\python\\ops\\array_grad.py:563: _EagerTensorBase.cpu (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.identity instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Y.Liu\\Anaconda3\\envs\\DeepLearning\\lib\\site-packages\\tensorflow_core\\python\\ops\\array_grad.py:563: _EagerTensorBase.cpu (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.identity instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving checkpoint for epoch 1 at E:\\Coding\\Projects\\transformer\\Data file\\checkpoints\\WMT19en-zh\\ckpt-1\n",
      "Epoch 1, Running time: 201.74, Train Loss 4.9183,Train Accuracy 0.0321\n",
      "Epoch 1, Running time: 201.74, Val Loss 3.7334,Val Accuracy 0.1062\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Saving checkpoint for epoch 2 at E:\\Coding\\Projects\\transformer\\Data file\\checkpoints\\WMT19en-zh\\ckpt-2\n",
      "Epoch 2, Running time: 146.69, Train Loss 3.1741,Train Accuracy 0.1615\n",
      "Epoch 2, Running time: 146.69, Val Loss 2.7112,Val Accuracy 0.2086\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Saving checkpoint for epoch 3 at E:\\Coding\\Projects\\transformer\\Data file\\checkpoints\\WMT19en-zh\\ckpt-3\n",
      "Epoch 3, Running time: 128.68, Train Loss 2.6154,Train Accuracy 0.2154\n",
      "Epoch 3, Running time: 128.68, Val Loss 2.2878,Val Accuracy 0.2569\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Saving checkpoint for epoch 4 at E:\\Coding\\Projects\\transformer\\Data file\\checkpoints\\WMT19en-zh\\ckpt-4\n",
      "Epoch 4, Running time: 131.55, Train Loss 2.2612,Train Accuracy 0.2573\n",
      "Epoch 4, Running time: 131.55, Val Loss 1.9484,Val Accuracy 0.3033\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Saving checkpoint for epoch 5 at E:\\Coding\\Projects\\transformer\\Data file\\checkpoints\\WMT19en-zh\\ckpt-5\n",
      "Epoch 5, Running time: 128.70, Train Loss 1.9894,Train Accuracy 0.2942\n",
      "Epoch 5, Running time: 128.70, Val Loss 1.7049,Val Accuracy 0.3388\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Saving checkpoint for epoch 6 at E:\\Coding\\Projects\\transformer\\Data file\\checkpoints\\WMT19en-zh\\ckpt-6\n",
      "Epoch 6, Running time: 126.47, Train Loss 1.7946,Train Accuracy 0.3217\n",
      "Epoch 6, Running time: 126.47, Val Loss 1.5251,Val Accuracy 0.3652\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Saving checkpoint for epoch 7 at E:\\Coding\\Projects\\transformer\\Data file\\checkpoints\\WMT19en-zh\\ckpt-7\n",
      "Epoch 7, Running time: 129.06, Train Loss 1.6242,Train Accuracy 0.3464\n",
      "Epoch 7, Running time: 129.06, Val Loss 1.3429,Val Accuracy 0.3929\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Saving checkpoint for epoch 8 at E:\\Coding\\Projects\\transformer\\Data file\\checkpoints\\WMT19en-zh\\ckpt-8\n",
      "Epoch 8, Running time: 131.61, Train Loss 1.4832,Train Accuracy 0.3659\n",
      "Epoch 8, Running time: 131.61, Val Loss 1.2004,Val Accuracy 0.4152\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Saving checkpoint for epoch 9 at E:\\Coding\\Projects\\transformer\\Data file\\checkpoints\\WMT19en-zh\\ckpt-9\n",
      "Epoch 9, Running time: 127.48, Train Loss 1.3835,Train Accuracy 0.3799\n",
      "Epoch 9, Running time: 127.48, Val Loss 1.0848,Val Accuracy 0.4332\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Saving checkpoint for epoch 10 at E:\\Coding\\Projects\\transformer\\Data file\\checkpoints\\WMT19en-zh\\ckpt-10\n",
      "Epoch 10, Running time: 131.31, Train Loss 1.3080,Train Accuracy 0.3905\n",
      "Epoch 10, Running time: 131.31, Val Loss 0.9915,Val Accuracy 0.4485\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Saving checkpoint for epoch 11 at E:\\Coding\\Projects\\transformer\\Data file\\checkpoints\\WMT19en-zh\\ckpt-11\n",
      "Epoch 11, Running time: 128.75, Train Loss 1.2495,Train Accuracy 0.3984\n",
      "Epoch 11, Running time: 128.75, Val Loss 0.9113,Val Accuracy 0.4623\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Saving checkpoint for epoch 12 at E:\\Coding\\Projects\\transformer\\Data file\\checkpoints\\WMT19en-zh\\ckpt-12\n",
      "Epoch 12, Running time: 124.65, Train Loss 1.2040,Train Accuracy 0.4043\n",
      "Epoch 12, Running time: 124.65, Val Loss 0.8422,Val Accuracy 0.4743\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Saving checkpoint for epoch 13 at E:\\Coding\\Projects\\transformer\\Data file\\checkpoints\\WMT19en-zh\\ckpt-13\n",
      "Epoch 13, Running time: 119.68, Train Loss 1.1690,Train Accuracy 0.4090\n",
      "Epoch 13, Running time: 119.68, Val Loss 0.7825,Val Accuracy 0.4851\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Saving checkpoint for epoch 14 at E:\\Coding\\Projects\\transformer\\Data file\\checkpoints\\WMT19en-zh\\ckpt-14\n",
      "Epoch 14, Running time: 127.59, Train Loss 1.1381,Train Accuracy 0.4124\n",
      "Epoch 14, Running time: 127.59, Val Loss 0.7279,Val Accuracy 0.4951\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Saving checkpoint for epoch 15 at E:\\Coding\\Projects\\transformer\\Data file\\checkpoints\\WMT19en-zh\\ckpt-15\n",
      "Epoch 15, Running time: 119.58, Train Loss 1.1144,Train Accuracy 0.4151\n",
      "Epoch 15, Running time: 119.58, Val Loss 0.6803,Val Accuracy 0.5042\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Saving checkpoint for epoch 16 at E:\\Coding\\Projects\\transformer\\Data file\\checkpoints\\WMT19en-zh\\ckpt-16\n",
      "Epoch 16, Running time: 119.70, Train Loss 1.0914,Train Accuracy 0.4185\n",
      "Epoch 16, Running time: 119.70, Val Loss 0.6377,Val Accuracy 0.5125\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Saving checkpoint for epoch 17 at E:\\Coding\\Projects\\transformer\\Data file\\checkpoints\\WMT19en-zh\\ckpt-17\n",
      "Epoch 17, Running time: 122.46, Train Loss 1.0726,Train Accuracy 0.4208\n",
      "Epoch 17, Running time: 122.47, Val Loss 0.5977,Val Accuracy 0.5205\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Saving checkpoint for epoch 18 at E:\\Coding\\Projects\\transformer\\Data file\\checkpoints\\WMT19en-zh\\ckpt-18\n",
      "Epoch 18, Running time: 124.69, Train Loss 1.0591,Train Accuracy 0.4226\n",
      "Epoch 18, Running time: 124.69, Val Loss 0.5623,Val Accuracy 0.5273\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Saving checkpoint for epoch 19 at E:\\Coding\\Projects\\transformer\\Data file\\checkpoints\\WMT19en-zh\\ckpt-19\n",
      "Epoch 19, Running time: 120.14, Train Loss 1.0448,Train Accuracy 0.4239\n",
      "Epoch 19, Running time: 120.14, Val Loss 0.5290,Val Accuracy 0.5343\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving checkpoint for epoch 20 at E:\\Coding\\Projects\\transformer\\Data file\\checkpoints\\WMT19en-zh\\ckpt-20\n",
      "Epoch 20, Running time: 123.08, Train Loss 1.0325,Train Accuracy 0.4254\n",
      "Epoch 20, Running time: 123.08, Val Loss 0.4986,Val Accuracy 0.5407\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Saving checkpoint for epoch 21 at E:\\Coding\\Projects\\transformer\\Data file\\checkpoints\\WMT19en-zh\\ckpt-21\n",
      "Epoch 21, Running time: 123.83, Train Loss 1.0218,Train Accuracy 0.4270\n",
      "Epoch 21, Running time: 123.84, Val Loss 0.4712,Val Accuracy 0.5468\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Saving checkpoint for epoch 22 at E:\\Coding\\Projects\\transformer\\Data file\\checkpoints\\WMT19en-zh\\ckpt-22\n",
      "Epoch 22, Running time: 122.32, Train Loss 1.0121,Train Accuracy 0.4281\n",
      "Epoch 22, Running time: 122.32, Val Loss 0.4459,Val Accuracy 0.5519\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Saving checkpoint for epoch 23 at E:\\Coding\\Projects\\transformer\\Data file\\checkpoints\\WMT19en-zh\\ckpt-23\n",
      "Epoch 23, Running time: 124.73, Train Loss 1.0029,Train Accuracy 0.4292\n",
      "Epoch 23, Running time: 124.73, Val Loss 0.4217,Val Accuracy 0.5572\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Saving checkpoint for epoch 24 at E:\\Coding\\Projects\\transformer\\Data file\\checkpoints\\WMT19en-zh\\ckpt-24\n",
      "Epoch 24, Running time: 127.82, Train Loss 0.9954,Train Accuracy 0.4300\n",
      "Epoch 24, Running time: 127.82, Val Loss 0.3998,Val Accuracy 0.5619\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Saving checkpoint for epoch 25 at E:\\Coding\\Projects\\transformer\\Data file\\checkpoints\\WMT19en-zh\\ckpt-25\n",
      "Epoch 25, Running time: 125.06, Train Loss 0.9877,Train Accuracy 0.4312\n",
      "Epoch 25, Running time: 125.06, Val Loss 0.3791,Val Accuracy 0.5668\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Saving checkpoint for epoch 26 at E:\\Coding\\Projects\\transformer\\Data file\\checkpoints\\WMT19en-zh\\ckpt-26\n",
      "Epoch 26, Running time: 120.34, Train Loss 0.9810,Train Accuracy 0.4320\n",
      "Epoch 26, Running time: 120.34, Val Loss 0.3594,Val Accuracy 0.5714\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Saving checkpoint for epoch 27 at E:\\Coding\\Projects\\transformer\\Data file\\checkpoints\\WMT19en-zh\\ckpt-27\n",
      "Epoch 27, Running time: 128.20, Train Loss 0.9761,Train Accuracy 0.4324\n",
      "Epoch 27, Running time: 128.20, Val Loss 0.3418,Val Accuracy 0.5752\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Saving checkpoint for epoch 28 at E:\\Coding\\Projects\\transformer\\Data file\\checkpoints\\WMT19en-zh\\ckpt-28\n",
      "Epoch 28, Running time: 120.17, Train Loss 0.9705,Train Accuracy 0.4333\n",
      "Epoch 28, Running time: 120.17, Val Loss 0.3246,Val Accuracy 0.5793\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Saving checkpoint for epoch 29 at E:\\Coding\\Projects\\transformer\\Data file\\checkpoints\\WMT19en-zh\\ckpt-29\n",
      "Epoch 29, Running time: 125.00, Train Loss 0.9636,Train Accuracy 0.4346\n",
      "Epoch 29, Running time: 125.00, Val Loss 0.3089,Val Accuracy 0.5828\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Saving checkpoint for epoch 30 at E:\\Coding\\Projects\\transformer\\Data file\\checkpoints\\WMT19en-zh\\ckpt-30\n",
      "Epoch 30, Running time: 120.08, Train Loss 0.9597,Train Accuracy 0.4350\n",
      "Epoch 30, Running time: 120.08, Val Loss 0.2935,Val Accuracy 0.5865\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Saving checkpoint for epoch 31 at E:\\Coding\\Projects\\transformer\\Data file\\checkpoints\\WMT19en-zh\\ckpt-31\n",
      "Epoch 31, Running time: 120.38, Train Loss 0.9560,Train Accuracy 0.4355\n",
      "Epoch 31, Running time: 120.38, Val Loss 0.2800,Val Accuracy 0.5897\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Saving checkpoint for epoch 32 at E:\\Coding\\Projects\\transformer\\Data file\\checkpoints\\WMT19en-zh\\ckpt-32\n",
      "Epoch 32, Running time: 123.69, Train Loss 0.9501,Train Accuracy 0.4361\n",
      "Epoch 32, Running time: 123.69, Val Loss 0.2666,Val Accuracy 0.5929\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Saving checkpoint for epoch 33 at E:\\Coding\\Projects\\transformer\\Data file\\checkpoints\\WMT19en-zh\\ckpt-33\n",
      "Epoch 33, Running time: 120.24, Train Loss 0.9471,Train Accuracy 0.4364\n",
      "Epoch 33, Running time: 120.24, Val Loss 0.2541,Val Accuracy 0.5960\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Saving checkpoint for epoch 34 at E:\\Coding\\Projects\\transformer\\Data file\\checkpoints\\WMT19en-zh\\ckpt-34\n",
      "Epoch 34, Running time: 120.24, Train Loss 0.9435,Train Accuracy 0.4370\n",
      "Epoch 34, Running time: 120.24, Val Loss 0.2422,Val Accuracy 0.5990\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Saving checkpoint for epoch 35 at E:\\Coding\\Projects\\transformer\\Data file\\checkpoints\\WMT19en-zh\\ckpt-35\n",
      "Epoch 35, Running time: 120.21, Train Loss 0.9415,Train Accuracy 0.4374\n",
      "Epoch 35, Running time: 120.22, Val Loss 0.2322,Val Accuracy 0.6014\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Saving checkpoint for epoch 36 at E:\\Coding\\Projects\\transformer\\Data file\\checkpoints\\WMT19en-zh\\ckpt-36\n",
      "Epoch 36, Running time: 120.45, Train Loss 0.9355,Train Accuracy 0.4384\n",
      "Epoch 36, Running time: 120.45, Val Loss 0.2216,Val Accuracy 0.6040\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Saving checkpoint for epoch 37 at E:\\Coding\\Projects\\transformer\\Data file\\checkpoints\\WMT19en-zh\\ckpt-37\n",
      "Epoch 37, Running time: 123.55, Train Loss 0.9321,Train Accuracy 0.4392\n",
      "Epoch 37, Running time: 123.55, Val Loss 0.2118,Val Accuracy 0.6068\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Saving checkpoint for epoch 38 at E:\\Coding\\Projects\\transformer\\Data file\\checkpoints\\WMT19en-zh\\ckpt-38\n",
      "Epoch 38, Running time: 120.51, Train Loss 0.9289,Train Accuracy 0.4397\n",
      "Epoch 38, Running time: 120.51, Val Loss 0.2030,Val Accuracy 0.6090\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving checkpoint for epoch 39 at E:\\Coding\\Projects\\transformer\\Data file\\checkpoints\\WMT19en-zh\\ckpt-39\n",
      "Epoch 39, Running time: 121.44, Train Loss 0.9275,Train Accuracy 0.4398\n",
      "Epoch 39, Running time: 121.44, Val Loss 0.1937,Val Accuracy 0.6111\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Saving checkpoint for epoch 40 at E:\\Coding\\Projects\\transformer\\Data file\\checkpoints\\WMT19en-zh\\ckpt-40\n",
      "Epoch 40, Running time: 120.98, Train Loss 0.9246,Train Accuracy 0.4398\n",
      "Epoch 40, Running time: 120.98, Val Loss 0.1854,Val Accuracy 0.6134\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "transformer.train(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 10060), started 4:47:10 ago. (Use '!kill 10060' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-12188afc0110ddcf\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-12188afc0110ddcf\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          url.port = 6006;\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## tensorboard visualization\n",
    "\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir {logdir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "## evaluate the sentence\n",
    "\n",
    "\"\"\"\n",
    "eval : A B C D ->E\n",
    "       A B C D E ->F\n",
    "       \n",
    "we don't need teacher forcing when doing evaluation,\n",
    "we add the latest prediction to the Chinese sequence Transformer \n",
    "     \n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def evaluate(inp_sentence):\n",
    "  \n",
    "    # add <start>, <end>\n",
    "    start_token = [subword_encoder_en.vocab_size]\n",
    "    end_token = [subword_encoder_en.vocab_size + 1]\n",
    "  \n",
    "    inp_sentence = start_token + subword_encoder_en.encode(inp_sentence) + end_token\n",
    "    \n",
    "    # encoder_input.shape == (1,inp_seq_len)\n",
    "    \n",
    "    encoder_input = tf.expand_dims(inp_sentence, 0) # add batch\n",
    "    \n",
    "    # decoder_input.shape == (1,1)\n",
    "    decoder_input = [subword_encoder_zh.vocab_size]\n",
    "    \n",
    "    output = tf.expand_dims(decoder_input, 0)  \n",
    "  \n",
    "    # auto-regressive, add the precidtion to seq and input to Transformer repeatly\n",
    "    \n",
    "    for i in range(max_len):\n",
    "        \n",
    "        # for every newly generated word create mask\n",
    "        \n",
    "        enc_padding_mask, combined_mask, dec_padding_mask = create_masks(\n",
    "                            encoder_input, output)\n",
    "  \n",
    "        # predictions.shape == (batch_size, seq_len, vocab_size)\n",
    "    \n",
    "        predictions, attention_weights = transformer(encoder_input, \n",
    "                                                    output,\n",
    "                                                    False,\n",
    "                                                    enc_padding_mask,\n",
    "                                                    combined_mask,\n",
    "                                                    dec_padding_mask)\n",
    "        \n",
    "        predictions = predictions[: , -1:, :]  # (batch_size, 1, vocab_size)\n",
    "\n",
    "        predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
    "    \n",
    "        # when get <end> token, then stop loop \n",
    "        \n",
    "        if tf.equal(predicted_id, subword_encoder_zh.vocab_size + 1):\n",
    "            \n",
    "            return tf.squeeze(output, axis=0), attention_weights \n",
    "     \n",
    "        # decoder can see the new predicted_id\n",
    "        output = tf.concat([output, predicted_id], axis=-1)\n",
    "\n",
    "        # get rid of batch dimension\n",
    "        \n",
    "    return tf.squeeze(output, axis=0), attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence: China, India and others have continuing economic growth.\n",
      "--------------------\n",
      "predicted_seq: tf.Tensor(\n",
      "[4201   16    4    2  386  101    8   34   32    4   33    1   22   52\n",
      "  107   84  377    5  521  292    3], shape=(21,), dtype=int32)\n",
      "--------------------\n",
      "predicted_sentence: 中国，印度和其他国家的经济增长仍在继续。\n"
     ]
    }
   ],
   "source": [
    "## translate\n",
    "\n",
    "sentence = \"China, India and others have continuing economic growth.\"\n",
    "\n",
    "predicted_seq, _ = evaluate(sentence)\n",
    "\n",
    "def translate(predicted_seq):\n",
    "    \n",
    "    target_vocab_size = subword_encoder_zh.vocab_size\n",
    "    predicted_seq_without_bos_eos = [idx for idx in predicted_seq if idx < target_vocab_size]\n",
    "    predicted_sentence = subword_encoder_zh.decode(predicted_seq_without_bos_eos)\n",
    "    \n",
    "    return predicted_sentence\n",
    "\n",
    "\n",
    "predicted_seq, _ = evaluate(sentence)\n",
    "predicted_sentence = translate(predicted_seq)\n",
    "print(\"sentence:\", sentence)\n",
    "print(\"-\" * 20)\n",
    "print(\"predicted_seq:\", predicted_seq)\n",
    "print(\"-\" * 20)\n",
    "print(\"predicted_sentence:\", predicted_sentence)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
